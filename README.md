# run experiment
# è®¾ç½®ç¯å¢ƒå˜é‡
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export CUDA_VISIBLE_DEVICES=0,2
export PYTHONPATH=./

# å¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹
pkill -9 -f run_experiment.py
# è¿è¡Œå®éªŒ
python ./src/run_experiment.py --config_path "local_usc16_config.yaml"

# SFTç‰ˆæœ¬ä¿®æ”¹loraé…ç½®
åœ¨configs/components/callbacks/test_time_training_callback.yamlè·¯å¾„ä¸‹å»ä¿®æ”¹ç›¸å…³å‚æ•°

# æ¸…ç†dockerå®¹å™¨
#!/bin/bash
echo "ğŸ§¹ æ¸…ç†æ‰€æœ‰ MySQL Docker å®¹å™¨..."

echo "åœæ­¢å®¹å™¨..."
docker stop $(docker ps -q --filter ancestor=mysql) 2>/dev/null

echo "åˆ é™¤å®¹å™¨..."
docker rm -f $(docker ps -aq --filter ancestor=mysql) 2>/dev/null

echo "âœ… æ¸…ç†å®Œæˆï¼å½“å‰ MySQL å®¹å™¨ï¼š"
docker ps -a | grep mysql || echo "æ— "

# è¿è¡Œllama3-8bçš„memory+å¬å›å®éªŒ
export DASHSCOPE_API_KEY=sk-30949268f306427886e6613da83a9e08
python ./src/run_experiment.py --config_path "configs/assignments/experiments/llama_31_8b_instruct/instance/db_bench/instance/trajectory_memory_usc16.yaml"

# è¿è¡Œtest-time-trainingåªè®­ç»ƒassistantéƒ¨åˆ†å®éªŒ
python ./src/run_experiment.py --config_path "configs/assignments/experiments/llama_31_8b_instruct/instance/db_bench/instance/sft_assistant_only.yaml"

# è¿è¡Œtest-time-trainingåªè®­ç»ƒassistantéƒ¨åˆ†+ åˆ©ç”¨å†å²4æ¡æˆåŠŸè½¨è¿¹å®éªŒ
python ./src/run_experiment.py --config_path "configs/assignments/experiments/llama_31_8b_instruct/instance/db_bench/instance/previous_sample_utilization_usc4.yaml"

# è¿è¡Œtest-time-trainingåªè®­ç»ƒassistantéƒ¨åˆ†+ memoryå¬å›
python ./src/run_experiment.py --config_path "configs/assignments/experiments/llama_31_8b_instruct/instance/db_bench/instance/sft_onlyassistant_memory.yaml"

# è¿è¡Œqwen2.5-7bçš„memoryç­–ç•¥
export DASHSCOPE_API_KEY=sk-30949268f306427886e6613da83a9e08
python ./src/run_experiment.py --config_path "configs/assignments/experiments/qwen25_7b_instruct/instance/db_bench/instance/memory.yaml"

# è¿è¡Œqwen2.5-7b standardç­–ç•¥
python ./src/run_experiment.py --config_path "configs/assignments/experiments/qwen25_7b_instruct/instance/db_bench/instance/standard.yaml"

# è¿è¡Œmemoryå®éªŒæ—¶è¦è®¾ç½®API KEYè°ƒç”¨qwen-plus
export DASHSCOPE_API_KEY=sk-30949268f306427886e6613da83a9e08


# ä¿®æ”¹è½¨è¿¹ç­–ç•¥ æ”¹ä¸ºç”¨embedding modelå¬å›ç›¸å…³è½¨è¿¹(4æ¡)
python ./src/run_experiment.py --config_path "configs/assignments/experiments/llama_31_8b_instruct/instance/db_bench/instance/previous_sample_embedding_usc4.yaml"

# è¿è¡Œæ­£å¸¸çš„è½¨è¿¹æ·»åŠ ä¸Šä¸‹æ–‡ç­–ç•¥
python ./src/run_experiment.py --config_path "configs/assignments/experiments/llama_31_8b_instruct/instance/db_bench/instance/previous_sample_utilization_usc1.yaml"

# è¿è¡Œembedding modelå¬å›ç›¸å…³è½¨è¿¹+tttå¢å¼º
python ./src/run_experiment.py --config_path "configs/assignments/experiments/llama_31_8b_instruct/instance/db_bench/instance/previous_sample_embedding_ttt_clean_usc4.yaml"

# è¿è¡Œåæ€è®°å¿†
export DASHSCOPE_API_KEY=sk-3c7d8138a66943ba9643ccebda724a00
python ./src/run_experiment.py --config_path "configs/assignments/experiments/llama_31_8b_instruct/instance/db_bench/instance/baseline_reflective_memory.yaml"

# è¿è¡Œtest-time-grpo-lora
python ./src/run_experiment.py --config_path "configs/assignments/experiments/llama_31_8b_instruct/instance/db_bench/instance/grpo_test_time_training.yaml"

# è¿è¡Œgrpo_lora
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export CUDA_VISIBLE_DEVICES=1,6  
export PYTHONPATH=./:./rllm
python ./src/run_experiment.py --config_path "configs/assignments/experiments/llama_31_8b_instruct/instance/db_bench/instance/grpo.yaml" --max_samples 100


# è¿è¡Œgrpo_lora+å†å²è½¨è¿¹
python ./src/run_experiment.py --config_path "configs/assignments/experiments/llama_31_8b_instruct/instance/db_bench/instance/grpo_with_history.yaml" --max_samples 1

# rllm_grpo
## è¿è¡Œå…ˆè´ªå¿ƒå† GRPO çš„è„šæœ¬
ä¾èµ–ï¼šæœ¬åœ° HF æƒé‡ã€CUDAã€Dockerï¼ˆMySQL é•œåƒï¼‰ã€‚
```bash
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export CUDA_VISIBLE_DEVICES=0,1  
export PYTHONPATH=./:./rllm
python3 -m src.rllm_integration.run_dbbench_greedy_grpo \
  --model_path /mnt/ssd2/models/Meta-Llama-3.1-8B-Instruct \
  --group_size 4 \
  --max_new_tokens 512 \
  --temperature 0.8 \
  --top_p 0.95 \
  --lora_r 16 --lora_alpha 32 --lora_dropout 0.05 \
  --learning_rate 2e-5 --weight_decay 0.01 \
  --beta 0.04 --clip_param 0.2 --grad_accum 1 --max_grad_norm 1.0 --num_epochs 1 \
  --reference_model_path /mnt/ssd2/models/Meta-Llama-3.1-8B-Instruct \
  --save_dir outputs/dbbench_grpo_lora
```

# LifelongAgentBench: Evaluating LLM Agents as Lifelong Learners

<p align="center">
    <img src="https://img.picui.cn/free/2025/05/21/682d857c0cb55.png" alt="Logo" width="80px">

[//]: # (    <br>)
[//]: # (    <b>WebArena is a standalone, self-hostable web environment for building autonomous agents</b>)
</p>

<p align="center">
<a href="https://www.python.org/downloads/release/python-3119/"><img src="https://img.shields.io/badge/python-3.11-blue.svg" alt="Python 3.11"></a>
<a href="https://pre-commit.com/"><img src="https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white" alt="pre-commit"></a>
<a href="https://github.com/psf/black"><img src="https://img.shields.io/badge/code%20style-black-000000.svg" alt="Code style: black"></a>
<a href="https://mypy-lang.org/"><img src="https://img.shields.io/badge/mypy-strict-blue" alt="Checked with mypy"></a>
</p>

<p align="center">
<a href="https://caixd-220529.github.io/LifelongAgentBench/">ProjectPage</a> â€¢
<a href="https://arxiv.org/abs/2505.11942">Paper</a> â€¢
<a href="https://huggingface.co/datasets/csyq/LifelongAgentBench">Dataset</a>
</p>

# Setup

```shell
git clone ...
cd continual_agent_bench
pip install -r requirements.txt
pip install pre-commit==4.0.1  # ensure that pre-commit hooks are installed
pre-commit install  # install pre-commit hooks
pre-commit run --all-files  # check its effect

docker pull mysql  # build images for db_bench

docker pull ubuntu  # build images for os_interaction
docker build -f scripts/dockerfile/os_interaction/default scripts/dockerfile/os_interaction --tag local-os/default
```

# Run experiments
If you want to run experiments in single machine mode, please use the following command:
```shell
export PYTHONPATH=./
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

python ./src/run_experiment.py --config_path "configs/assignments/experiments/llama_31_8b_instruct/instance/db_bench/instance/standard.yaml"
```

If you want to run experiments in distributed mode, you first need to start the `ServerSideController` in the machine that can deploy the docker containers.
```shell
export PYTHONPATH=./

python src/distributed_deployment_utils/server_side_controller/main.py
```
Then, you can run the following command in HPC node.
```shell
export PYTHONPATH=./
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

python src/distributed_deployment_utils/run_experiment_remotely.py --config_path "configs/assignments/experiments/llama_31_8b_instruct/instance/db_bench/instance/standard.yaml"
```
The `ServerSideController` can be reused for multiple experiments.
> [!NOTE]
> Don't forget to update the IP address in `configs/components/environment.yaml` as well as in the files under `configs/components/clients`.