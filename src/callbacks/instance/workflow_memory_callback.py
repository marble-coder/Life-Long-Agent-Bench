"""
Workflow Memory Callback - åŸºäºŽ AWM Online æ–¹æ³•çš„å·¥ä½œæµè®°å¿†æœºåˆ¶
å‚è€ƒ: Agent Workflow Memory (https://arxiv.org/abs/2409.07429)

æ ¸å¿ƒç‰¹æ€§ï¼š
- ä½¿ç”¨ Agent å½“å‰çš„ LanguageModel è¿›è¡Œ workflow å½’çº³ï¼ˆè‡ªå½’çº³ï¼‰
- è‡ªåŠ¨æ”¶é›†æˆåŠŸæ ·æœ¬å¹¶å®šæœŸå½’çº³
- å°†å½’çº³çš„ workflow æ³¨å…¥åˆ°åŽç»­ä»»åŠ¡çš„ prompt ä¸­
- å®žæ—¶æ‰“å°å½’çº³çš„ workflows åˆ°æŽ§åˆ¶å°
"""

from typing import Optional, List
from abc import ABC, abstractmethod
import os
import json

from src.callbacks import Callback, CallbackArguments
from src.typings import (
    Session, 
    SampleStatus, 
    SessionEvaluationOutcome, 
    ChatHistoryItem, 
    Role,
    ChatHistory,
)
from src.language_models import LanguageModel
from src.utils import SafeLogger


class WorkflowMemoryCallback(Callback, ABC):
    """
    æŠ½è±¡åŸºç±»ï¼šå®žçŽ° AWM Online çš„å·¥ä½œæµå½’çº³å’Œåˆ©ç”¨æœºåˆ¶
    
    æ ¸å¿ƒæµç¨‹ (ä¸Ž AWM åŽŸå§‹å®žçŽ°ä¸€è‡´):
    1. æ”¶é›†æˆåŠŸçš„æ‰§è¡Œè½¨è¿¹
    2. æ¯ N ä¸ªæ ·æœ¬åŽä½¿ç”¨ Agent çš„æ¨¡åž‹å½’çº³ workflow
    3. å°† workflow æ³¨å…¥åˆ°åŽç»­ä»»åŠ¡çš„ prompt ä¸­
    """
    
    def __init__(
        self,
        induction_frequency: int = 5,      # æ¯ N ä¸ªæ ·æœ¬å½’çº³ä¸€æ¬¡
        max_workflows: int = 10,            # æœ€å¤šä¿ç•™çš„ workflow æ•°é‡
        min_success_samples: int = 2,       # æœ€å°‘éœ€è¦çš„æˆåŠŸæ ·æœ¬æ•°
        max_examples_for_induction: int = 10,  # ç”¨äºŽå½’çº³çš„æœ€å¤§ç¤ºä¾‹æ•°
        workflow_file_name: str = "workflows.txt",
        temperature: float = 0.0,           # å‘åŽå…¼å®¹ï¼Œä»ç„¶æ”¯æŒå•ç‹¬çš„ temperature
        use_previous_workflows: bool = False,  # AWM ä¸ä½¿ç”¨ä¹‹å‰çš„ workflows
        instruction_file: Optional[str] = None,  # å½’çº³æŒ‡ä»¤æ–‡ä»¶è·¯å¾„
        one_shot_file: Optional[str] = None,     # One-shot ç¤ºä¾‹æ–‡ä»¶è·¯å¾„
        inference_config_dict: Optional[dict] = None,  # å®Œæ•´çš„æŽ¨ç†é…ç½®ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰
    ):
        super().__init__()
        self.induction_frequency = induction_frequency
        self.max_workflows = max_workflows
        self.min_success_samples = min_success_samples
        self.max_examples_for_induction = max_examples_for_induction
        self.workflow_file_name = workflow_file_name
        self.temperature = temperature
        self.use_previous_workflows = use_previous_workflows
        
        # å¦‚æžœæä¾›äº†å®Œæ•´çš„ inference_config_dictï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™æ ¹æ® temperature æž„å»º
        if inference_config_dict is not None:
            self.inference_config_dict = inference_config_dict
        else:
            # å‘åŽå…¼å®¹ï¼šæ ¹æ® temperature è‡ªåŠ¨æž„å»ºé…ç½®
            if temperature == 0.0:
                self.inference_config_dict = {
                    "do_sample": False,
                    "num_beams": 1,
                    "max_new_tokens": 2048,
                }
            else:
                self.inference_config_dict = {
                    "do_sample": True,
                    "temperature": temperature,
                    "max_new_tokens": 2048,
                }
        self.instruction_file = instruction_file
        self.one_shot_file = one_shot_file
        
        # çŠ¶æ€å˜é‡
        self.successful_sessions: List[Session] = []
        self.workflows: List[str] = []
        self.processed_count = 0
        self.induction_count = 0
        
        # LanguageModel å°†åœ¨è¿è¡Œæ—¶ç”± Agent æä¾›
        self._language_model: Optional[LanguageModel] = None
        
    @classmethod
    def is_unique(cls) -> bool:
        return True
    
    def restore_state(self) -> None:
        """ä»Žä¿å­˜çš„çŠ¶æ€ä¸­æ¢å¤"""
        state_file = os.path.join(self.get_state_dir(), "workflow_memory_state.json")
        if os.path.exists(state_file):
            with open(state_file, 'r', encoding='utf-8') as f:
                state = json.load(f)
                self.processed_count = state.get("processed_count", 0)
                self.induction_count = state.get("induction_count", 0)
                self.workflows = state.get("workflows", [])
                SafeLogger.info(
                    f"[WorkflowMemory] æ¢å¤çŠ¶æ€: {self.processed_count} ä¸ªå·²å¤„ç†æ ·æœ¬, "
                    f"{len(self.workflows)} ä¸ª workflows"
                )
        
        workflow_file = self._get_workflow_file_path()
        if os.path.exists(workflow_file):
            with open(workflow_file, 'r', encoding='utf-8') as f:
                content = f.read()
                self.workflows = [wf.strip() for wf in content.split('\n\n') if wf.strip()]
    
    def on_task_reset(self, callback_args: CallbackArguments) -> None:
        """
        ä»»åŠ¡é‡ç½®æ—¶ï¼š
        1. ä»Ž Agent èŽ·å– LanguageModel
        2. å°† workflows æ³¨å…¥åˆ°ç¬¬ä¸€æ¡ USER æ¶ˆæ¯ï¼ˆç³»ç»ŸæŒ‡ä»¤ï¼‰ä¸­
        """
        agent = callback_args.session_context.agent
        
        # 1. èŽ·å– LanguageModel
        if hasattr(agent, '_language_model'):
            self._language_model = agent._language_model
            SafeLogger.debug(
                f"[WorkflowMemory] èŽ·å–åˆ° Agent çš„æ¨¡åž‹å¼•ç”¨: "
                f"{type(self._language_model).__name__}"
            )
        elif hasattr(agent, 'language_model'):
            self._language_model = agent.language_model
            SafeLogger.debug(
                f"[WorkflowMemory] èŽ·å–åˆ° Agent çš„æ¨¡åž‹å¼•ç”¨: "
                f"{type(self._language_model).__name__}"
            )
        else:
            SafeLogger.warning("[WorkflowMemory] Agent æ²¡æœ‰ language_model æˆ– _language_model å±žæ€§")
        
        # 2. æ³¨å…¥ workflows åˆ°ç¬¬ä¸€æ¡ USER æ¶ˆæ¯æœ«å°¾
        if len(self.workflows) > 0:
            task = callback_args.session_context.task
            
            # èŽ·å–å½“å‰çš„ç¬¬ä¸€æ¡ USER æ¶ˆæ¯
            try:
                current_first_prompt = task.chat_history_item_factory.construct(0, Role.USER).content
            except Exception as e:
                SafeLogger.warning(f"[WorkflowMemory] æ— æ³•èŽ·å–ç¬¬ä¸€æ¡ USER æ¶ˆæ¯: {e}")
                return
            
            # å®šä¹‰ workflow section çš„æ ‡è®°
            workflow_marker = "\n\n" + "=" * 80 + "\n" + "Here are some useful skills abstracted from previous successful trajectories:"
            
            # ç§»é™¤æ—§çš„ workflow sectionï¼ˆå¦‚æžœå­˜åœ¨ï¼‰
            if workflow_marker in current_first_prompt:
                original_first_prompt = current_first_prompt.split(workflow_marker)[0]
                SafeLogger.debug(f"[WorkflowMemory] æ£€æµ‹åˆ°æ—§çš„ workflow sectionï¼Œå·²ç§»é™¤")
            else:
                original_first_prompt = current_first_prompt
            
            # æž„å»ºæ–°çš„ workflow æç¤ºï¼ˆæ·»åŠ åˆ°ç³»ç»ŸæŒ‡ä»¤æœ«å°¾ï¼‰
            workflow_section = "\n\n" + "=" * 80 + "\n"
            workflow_section += "Here are some useful skills abstracted from previous successful trajectories:\n"
            workflow_section += "You can refer to these patterns when solving similar problems.\n\n"
            
            # æ·»åŠ æ¯ä¸ª workflow
            for workflow in self.workflows:
                workflow_section += workflow + "\n\n"
            
            workflow_section += "=" * 80
            
            # æž„å»ºå¢žå¼ºçš„ promptï¼ˆworkflows åœ¨æœ«å°¾ï¼‰
            enhanced_prompt = original_first_prompt + workflow_section
            
            # æ›´æ–°ç¬¬ä¸€æ¡ USER æ¶ˆæ¯
            task.chat_history_item_factory.set(0, Role.USER, enhanced_prompt)
            
            SafeLogger.info(
                f"[WorkflowMemory] âœ… æ›´æ–°ç³»ç»ŸæŒ‡ä»¤ä¸­çš„ workflows (å…± {len(self.workflows)} ä¸ª) "
                f"(æ ·æœ¬ {callback_args.current_session.sample_index}), "
                f"åŽŸå§‹: {len(original_first_prompt)} å­—ç¬¦ â†’ å¢žå¼ºåŽ: {len(enhanced_prompt)} å­—ç¬¦"
            )
    
    def on_task_complete(self, callback_args: CallbackArguments) -> None:
        """æ”¶é›†æˆåŠŸæ ·æœ¬å¹¶æ£€æŸ¥æ˜¯å¦éœ€è¦å½’çº³"""
        session = callback_args.current_session
        
        # åªæ”¶é›†æˆåŠŸçš„æ ·æœ¬ (ä¸Ž AWM ä¸€è‡´)
        if (session.sample_status == SampleStatus.COMPLETED and 
            session.evaluation_record.outcome == SessionEvaluationOutcome.CORRECT):
            self.successful_sessions.append(session.model_copy(deep=True))
            SafeLogger.info(
                f"[WorkflowMemory] æ”¶é›†æˆåŠŸæ ·æœ¬ {session.sample_index}, "
                f"æˆåŠŸæ ·æœ¬æ•°: {len(self.successful_sessions)}"
            )
        
        self.processed_count += 1
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å½’çº³
        should_induce = (
            self.processed_count % self.induction_frequency == 0 and 
            len(self.successful_sessions) >= self.min_success_samples and
            self._language_model is not None
        )
        
        if should_induce:
            SafeLogger.info(f"[WorkflowMemory] å¼€å§‹ç¬¬ {self.induction_count + 1} æ¬¡å½’çº³...")
            self._induce_workflows()
    
    def on_agent_inference(self, callback_args: CallbackArguments) -> None:
        """
        æ³¨å…¥åˆ°ç¬¬ä¸€æ¡ USER æ¶ˆæ¯åŽï¼Œè¿™ä¸ªæ–¹æ³•å°±ä¸éœ€è¦äº†
        workflows å·²ç»åœ¨ on_task_reset ä¸­æ³¨å…¥åˆ°ç³»ç»ŸæŒ‡ä»¤äº†
        """
        pass
    
    def on_state_save(self, callback_args: CallbackArguments) -> None:
        """ä¿å­˜çŠ¶æ€"""
        state_file = os.path.join(self.get_state_dir(), "workflow_memory_state.json")
        state = {
            "processed_count": self.processed_count,
            "induction_count": self.induction_count,
            "workflows": self.workflows,
            "successful_count": len(self.successful_sessions),
        }
        
        os.makedirs(os.path.dirname(state_file), exist_ok=True)
        with open(state_file, 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=2, ensure_ascii=False)
        
        if len(self.workflows) > 0:
            workflow_file = self._get_workflow_file_path()
            os.makedirs(os.path.dirname(workflow_file), exist_ok=True)
            with open(workflow_file, 'w', encoding='utf-8') as f:
                f.write('\n\n'.join(self.workflows))
    
    def _induce_workflows(self) -> None:
        """è°ƒç”¨ LLM å½’çº³ workflows (éµå¾ª AWM çš„æ–¹å¼)"""
        if self._language_model is None:
            SafeLogger.error("[WorkflowMemory] æ¨¡åž‹æœªè®¾ç½®")
            return
        
        try:
            # é€‰æ‹©ç¤ºä¾‹
            examples = self.successful_sessions[-self.max_examples_for_induction:]
            SafeLogger.info(f"[WorkflowMemory] ä½¿ç”¨ {len(examples)} ä¸ªæ ·æœ¬å½’çº³")
            
            # æ ¼å¼åŒ–ç¤ºä¾‹ (å­ç±»å®žçŽ°)
            formatted = self._format_successful_sessions(examples)
            
            # æž„é€  prompt (éµå¾ª AWM çš„ç»“æž„)
            prompt = self._build_awm_style_prompt(formatted)
            
            # è°ƒç”¨ LLM
            chat_history = ChatHistory()
            chat_history.inject(ChatHistoryItem(role=Role.USER, content=prompt))
            
            SafeLogger.info(
                f"[WorkflowMemory] è°ƒç”¨ LLM å½’çº³ "
                f"(config={self.inference_config_dict})..."
            )
            
            response = self._language_model.inference(
                batch_chat_history=[chat_history],
                inference_config_dict=self.inference_config_dict,
                system_prompt="You are an expert at extracting common patterns from task executions."
            )[0]
            
            # è§£æž workflows
            new_workflows = self._parse_workflows(response.content)
            
            if len(new_workflows) > 0:
                self.workflows.extend(new_workflows)
                if len(self.workflows) > self.max_workflows:
                    self.workflows = self.workflows[-self.max_workflows:]
                
                SafeLogger.info(
                    f"[WorkflowMemory] å½’çº³å¾—åˆ° {len(new_workflows)} ä¸ªæ–° workflows, "
                    f"æ€»æ•°: {len(self.workflows)}"
                )
                
                # ðŸŽ¯ æ‰“å°æ–°å½’çº³çš„ workflows åˆ°æŽ§åˆ¶å°
                self._print_workflows_to_console(new_workflows)
                
            else:
                SafeLogger.warning("[WorkflowMemory] LLM æ²¡æœ‰ç”Ÿæˆä»»ä½• workflow")
            
            self.induction_count += 1
            
            # ä¿ç•™éƒ¨åˆ†æ ·æœ¬
            keep = min(self.induction_frequency, len(self.successful_sessions))
            self.successful_sessions = self.successful_sessions[-keep:]
            
        except Exception as e:
            SafeLogger.error(f"[WorkflowMemory] å½’çº³å¤±è´¥: {e}", exc_info=True)
    
    def _print_workflows_to_console(self, workflows: List[str]) -> None:
        """
        æ‰“å°æ–°å½’çº³çš„ workflows åˆ°æŽ§åˆ¶å°
        ä½¿ç”¨æ¼‚äº®çš„æ ¼å¼æ–¹ä¾¿é˜…è¯»
        """
        separator = "=" * 80
        SafeLogger.info(f"\n{separator}")
        SafeLogger.info(f"ðŸŽ¯ ç¬¬ {self.induction_count + 1} æ¬¡å½’çº³ - æ–°ç”Ÿæˆçš„ Workflows:")
        SafeLogger.info(separator)
        
        for idx, workflow in enumerate(workflows, 1):
            SafeLogger.info(f"\nðŸ“‹ Workflow {idx}:")
            SafeLogger.info("-" * 80)
            # é€è¡Œæ‰“å° workflowï¼Œä¿æŒæ ¼å¼
            for line in workflow.split('\n'):
                SafeLogger.info(f"  {line}")
            SafeLogger.info("")
        
        SafeLogger.info(separator)
        SafeLogger.info(f"âœ… æœ¬æ¬¡å½’çº³å®Œæˆï¼å½“å‰å…±æœ‰ {len(self.workflows)} ä¸ª workflows")
        SafeLogger.info(f"{separator}\n")
    
    def _build_awm_style_prompt(self, formatted_examples: str) -> str:
        """
        æž„é€  AWM é£Žæ ¼çš„ prompt
        ç»“æž„: INSTRUCTION + ONE_SHOT + formatted_examples + "# Summary Workflows"
        """
        components = []
        
        # 1. INSTRUCTION
        instruction = self._load_instruction()
        components.append(instruction)
        
        # 2. ONE_SHOT (å¯é€‰)
        one_shot = self._load_one_shot()
        if one_shot:
            components.append(one_shot)
        
        # 3. Formatted Examples
        components.append(formatted_examples)
        
        # 4. Summary marker
        components.append("# Summary Workflows")
        
        return '\n\n'.join(components)
    
    def _load_instruction(self) -> str:
        """åŠ è½½å½’çº³æŒ‡ä»¤"""
        if self.instruction_file and os.path.exists(self.instruction_file):
            with open(self.instruction_file, 'r', encoding='utf-8') as f:
                return f.read().strip()
        return self._get_default_instruction()
    
    def _load_one_shot(self) -> str:
        """åŠ è½½ one-shot ç¤ºä¾‹"""
        if self.one_shot_file and os.path.exists(self.one_shot_file):
            with open(self.one_shot_file, 'r', encoding='utf-8') as f:
                return f.read().strip()
        return ""
    
    # ========== å­ç±»å¿…é¡»å®žçŽ°çš„æŠ½è±¡æ–¹æ³• ==========
    
    @abstractmethod
    def _format_successful_sessions(self, sessions: List[Session]) -> str:
        """æ ¼å¼åŒ–æˆåŠŸçš„ä¼šè¯ä¸º AWM é£Žæ ¼çš„ç¤ºä¾‹"""
        raise NotImplementedError()
    
    @abstractmethod
    def _parse_workflows(self, llm_response: str) -> List[str]:
        """è§£æž LLM å“åº”ä¸­çš„ workflows"""
        raise NotImplementedError()
    
    @abstractmethod
    def _format_workflows_for_prompt(self) -> str:
        """æ ¼å¼åŒ– workflows ç”¨äºŽæ³¨å…¥åˆ° Agent prompt"""
        raise NotImplementedError()
    
    @abstractmethod
    def _get_default_instruction(self) -> str:
        """èŽ·å–é»˜è®¤çš„å½’çº³æŒ‡ä»¤ (å¦‚æžœæ–‡ä»¶ä¸å­˜åœ¨)"""
        raise NotImplementedError()
    
    # ========== è¾…åŠ©æ–¹æ³• ==========
    
    def _get_workflow_file_path(self) -> str:
        return os.path.join(self.get_state_dir(), self.workflow_file_name)

